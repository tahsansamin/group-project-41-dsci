{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41654b-c5cc-43a1-8ef6-bc1be1be257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(c(\"tidymodels\"))\n",
    "#install.packages(\"kknn\")\n",
    "\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(themis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728af3e0-1cb3-4296-8825-a12e07b93998",
   "metadata": {},
   "source": [
    "## DSCI 100 Group Project:\n",
    "Group members(UBC student number): Tahsan Samin (15680358), Charlene Tam (90063090), Tania Ghassemi, Octave Moha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbdd0b5-4247-4927-9287-d0bab62399de",
   "metadata": {},
   "source": [
    "### Title: Predicting player subscription status to a game related newsletter using the number of hours played and the age of the players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be03039-0c7f-45d4-acc2-e0f6714b9395",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "#### Data Source\n",
    "The dataset that will be explored today concerns itself with how people play video games and related behaviours. The data was collected by [a research group at UBC](https://plai.cs.ubc.ca/) from [their self-built MineCraft server](https://plaicraft.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd60b6-2de1-4b1a-94d8-2ffe4d456e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "players <- read_csv(\"https://raw.githubusercontent.com/tahsansamin/group-project-41-dsci/refs/heads/main/players.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1272afac-d3f9-4395-8afc-d7af2c241da4",
   "metadata": {},
   "source": [
    "#### Variable Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0286c-d674-433f-9e62-29c63fad8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please run the code below to see a summary of statistics\n",
    "summary(players)\n",
    "\n",
    "mean_table <- players |>\n",
    "    summarize(\n",
    "        \"Played Hours\" = round(mean(played_hours, na.rm = TRUE), 2),\n",
    "        \"Age\" = round(mean(Age, na.rm = TRUE), 2)\n",
    "    ) |>\n",
    "    pivot_longer(\n",
    "        cols = everything(),\n",
    "        names_to = \"Variable\",\n",
    "        values_to = \"Mean\"\n",
    "    )\n",
    "mean_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406ddaf-0b2d-4edb-974f-cac71fe3174b",
   "metadata": {},
   "source": [
    "According to the `summary()` output above, the data set `players.csv`contains **196 observations**, where each observation represents a unique player, and **7 variables**:\n",
    "- **Character**: `experience`, `hashedEmail`, `name`, `gender`\n",
    "- **Numeric**: `played_hours`, `Age`\n",
    "- **Logical**: `subscribe`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077602de-cc46-4a08-bc21-a4183f80a013",
   "metadata": {},
   "source": [
    "#### Description of the variables\n",
    "1. **experience**: players experience in 5 categories: Pro, Veteran, Amateur, Regular and Beginner.\n",
    "2. **susbcribe**: TRUE if player has subscribed to newsletter and FALSE otherwise.\n",
    "3. **hashedEmail**: encrypted email address of player. \n",
    "4. **played_hours**: number of hours spent on the game by the player.  \n",
    "5. **name**: name of player.\n",
    "6. **gender**: gender of player with unique values: male , female, non-binary, prefer not to say, agender, two-spirited or other.\n",
    "7. **Age of player**: age of the player."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e8d2a-96f1-4934-873a-d753ea8d9b13",
   "metadata": {},
   "source": [
    "#### Visible Issues\n",
    "- The `Age` variable is missing 2 values, which will need to be handled with code such as `na.rm = TRUE`, removing the observations with the missing values altogether or imputing the missing values before modeling.\n",
    "- All `character` variables will need to be converted to be used correctly in a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32bd43-4d62-42ad-b1a1-fa92107c5172",
   "metadata": {},
   "source": [
    "#### Invisible Issues\n",
    "- We only have data on 196 players who found and chose to join this research. This does not necessarily generalize data about *all* players. \n",
    "- The `experience`, `gender`, and `Age` variables were self-reported, which could lead to potential noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dbb422-71be-4c40-8189-5748070ba60f",
   "metadata": {},
   "source": [
    "#### Broad question\n",
    "Question 1: \"What player characteristics and behaviours are most predictive of subscribing to a game-related newsletter, and how do these features differ between various player types?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26072810-0115-4fe7-ac2b-76f16ff31408",
   "metadata": {},
   "source": [
    "#### Specific Question\n",
    "##### \"How can a player's `played_hours`and `Age` be used to predict their likelihood of subscribing (true or false for `subscribe`) to a game related newsletter?\" \n",
    "\n",
    "The `played_hours`and `Age` variables are chosen because logically it is expected that individuals who play for longer hours are more likely to subscribe to a game-related newsletter. Also, younger individuals are more likely to spend more hours playing the video game than older individuals and are subsequently more likely to subscribe to the newsletter.\n",
    "\n",
    "Most importantly, `played_hours`and `Age` are numerical values where we can directly apply `k-NN classification` on prediction, while `experience` and `gender` have to be converted before predicting. The rest of the variables, including `hashedEmail` and `name`, are unique to each player, which means they would not be a possible predictor option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f14724-2577-46f0-a984-00876618c917",
   "metadata": {},
   "source": [
    "#### Data Plan\n",
    "The `players.csv` dataset will be a perfect fit for answering our question, as it contains all the required variables.\n",
    "\n",
    "To apply a `k-NN` model, the data must be wrangled in the following ways:\n",
    "\n",
    "1. Drop the observations with the 2 missing `Age` values.\n",
    "2. Select only the `played_hours`, `Age` and `subscribe` variables.\n",
    "3. Standardize all numeric predictors so that they are on a common scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb9195-ab36-4536-979c-89a679f23250",
   "metadata": {},
   "source": [
    "### Methods and Results\n",
    "For our project `k-NN classification` will be used because our selected player variables (`Age` and `played_hours`) are numerical and our target variable (`subscribe`) is categorical. From `players.csv`, the rows with `NA` values will be removed and only `Age`, `played_hours`, and `subscribe` will be selected. \n",
    "\n",
    "The data will be split into **75% training data** and **25% testing data**. **5-fold cross-validation** with a range of Ks will be used to select the model based on the highest cross-validation accuracy. We will use 5 folds because of computational efficiency.\n",
    "\n",
    "#### Loading and wrangling the dataset into a tidy format\n",
    "The dataset already satisfies all criteria for being tidy. We decided to drop the two observations with `NA` values because they are such a small number of observations that it is unlikely to cause loss of valuable information. The two `NA` observations are `NA` in the age column. Looking at their reading for the number of hours played (0.1 hours and 0.2 hours), the readings do not appear to be extreme cases, further proving that dropping `NA` values would probably not cause loss of valuable data. We will also change the subscription status into the factor data type to make it suitable for `k-NN classification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b64167-bd7c-4937-9392-9d215cad3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_na <- sum(is.na(players))\n",
    "is_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf17069-71f3-4378-b984-3d43c8ac53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "narows <- players[!complete.cases(players),]\n",
    "narows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde87c6-d0d8-4447-a7ae-6443de146b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "players <- drop_na(players)\n",
    "players <- players |> mutate(subscribe = as_factor(subscribe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be434fb9-6e26-4460-bc55-08b4081dd76e",
   "metadata": {},
   "source": [
    "#### Summary of the players dataset\n",
    "We will now perform a statistical summary of the numerical variables in the players dataset. Right away it is clear that we may be dealing with a few outliers for the number of hours played variable because it has such a large range from **0 hours** to **223.10 hours** but such a small `mean` of **5.85 hours**. This is something that should be kept in mind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d16a52-cbb8-45dd-9d16-7d1840dd9f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats_players <- players |> \n",
    "                summarise(min_Age = min(Age, na.rm = TRUE),max_Age = max(Age, na.rm = TRUE),mean_age = mean(Age, na.rm = TRUE), min_played_hours = min(played_hours),max_played_hours = max(played_hours), \n",
    "                         , mean_played_hours = mean(played_hours, na.rm = TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de91695b-673f-4f11-a23a-e318e3d4a0ba",
   "metadata": {},
   "source": [
    "#### Players.csv\n",
    "\n",
    "| Variable | Minimum | Maximum | Mean |\n",
    "| -------- | ------- | -------- | -----|\n",
    "| Age | 9.00 | 58.00 | 21.14 |\n",
    "| played_hours | 0.00 | 223.10 | 5.85 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec4fe57-a94d-466d-925a-af742f39a4c7",
   "metadata": {},
   "source": [
    "#### Visualization of the players dataset\n",
    "Below is a scatter plot of the number of hours played versus the age of the player. We log scaled the y axis to make the data points more visible. As was suspected before, there are a few outliers for the number of hours played. For now we will do the KNN classification algorithm with these outliers to see if they actually have a negative impact on our results. Furthermore, there seems to be a class imbalance with more observations for true subscription statuses. For now we will attempt the KNN classification algorithm without accounting for this to try and see if it actually negatively impacts our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e56a64-333e-4e3d-84d6-1f8a2e4eb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_1 <- players |>\n",
    "            ggplot(aes(x = Age, y= log1p(played_hours), color = subscribe)) +\n",
    "            geom_point() +\n",
    "            labs(x = \"Age of the Player\", y = \"Logarithm of (1 plus number of hours played)\", title = \"(Figure 1) Number of Hours played against the Age of Player\") +\n",
    "            theme(text = element_text(size = 14)) \n",
    "#log1p was added after discussion with a TA on how to make both variables on comparable scales.\n",
    "#standardising and centering the variables did not work in making the variables comparable so log1p was suggested by the TA\n",
    "figure_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b73a25-79ec-4650-a27a-3b9b161eb4ad",
   "metadata": {},
   "source": [
    "#### Data analysis\n",
    "##### Splitting the dataset into training and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba58d01-0af7-480b-a3ae-ec705d9a6196",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9999) \n",
    "game_split <- initial_split(players, prop = 0.75, strata = subscribe)  \n",
    "game_train <- training(game_split)\n",
    "game_test <- testing(game_split)\n",
    "head(game_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7a4c8-5841-4fcd-aab7-ef5c82e2d870",
   "metadata": {},
   "source": [
    "Next we will create the recipe to be applied on our dataset for KNN classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b50193-2ace-4bfd-b811-057acb688472",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_recipe <- recipe(subscribe ~ played_hours + Age , data = game_train) |>\n",
    "   step_scale(all_predictors()) |>\n",
    "   step_center(all_predictors())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c97b3-9fd6-4c9d-afbc-21550e9daf6d",
   "metadata": {},
   "source": [
    "Next we will create our model specification and prepare the data for cross validation. A range of values from 1 to 15 was selected for tuning the number of neighbors. Conventionally a range of K values from 1 up to the value for the square root of the dataset size is used. Our dataset size 196 and the square root of it is 14, so we decided to use a range of Ks from 1 to 15. Furthermore, we think that this range is computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8990a-46c1-4c5e-a563-3b39106fdae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234) \n",
    "game_vfold <- vfold_cv(game_train, v = 5, strata = subscribe)\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 15, by = 1))\n",
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "            set_engine(\"kknn\") |>\n",
    "            set_mode(\"classification\")\n",
    "knn_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a42930-3f19-48e5-9182-d44883fde687",
   "metadata": {},
   "source": [
    "We will now perform the 5 cross fold validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae620828-d3cc-41bf-a7f1-bd15c7380e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2456)\n",
    "knn_results <- workflow() |>\n",
    "      add_recipe(game_recipe) |>\n",
    "      add_model(knn_tune) |>\n",
    "      tune_grid(resamples = game_vfold, grid = k_vals) |>\n",
    "      collect_metrics()\n",
    "head(knn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99fcf7-14d2-4e56-8ab0-2fe3b2d481e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies <- knn_results |> \n",
    "      filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracy_versus_k <- ggplot(accuracies, aes(x = neighbors, y = mean))+\n",
    "      geom_point() +\n",
    "      geom_line() +\n",
    "      labs(x = \"Neighbors\", y = \"Accuracy Estimate\", title = \"(Figure 2) Accuracy estimate for a range of values of K\") +\n",
    "      scale_x_continuous(breaks = seq(0, 15, by = 1)) +  # adjusting the x-axis\n",
    "      scale_y_continuous(limits = c(0.4, 1.0)) +\n",
    "       theme(text = element_text(size = 14))# adjusting the y-axis\n",
    "\n",
    "accuracy_versus_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc5d6ed-0c83-49ad-844e-9041dceb1469",
   "metadata": {},
   "source": [
    "A K value of 15 neighbors seems to give the highest accuracy with a value just above 70%.\n",
    "We will next re train a new KNN classification model with K = 15 and use that to perform predictions on the testing dataset to evaluate our model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9336fcb-0749-42c9-9dcf-7d90685fd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9999) \n",
    "new_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 15) |>\n",
    "       set_engine(\"kknn\") |>\n",
    "       set_mode(\"classification\")\n",
    "\n",
    "game_fit <- workflow() |>\n",
    "             add_recipe(game_recipe) |>\n",
    "             add_model(new_spec) |>\n",
    "            fit(data = game_train)\n",
    "game_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5012338f-7266-497f-807d-75e4236b5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9999) \n",
    "\n",
    "\n",
    "game_predictions <- predict(game_fit, game_test) |>\n",
    "                        bind_cols(game_test)\n",
    "\n",
    "game_metrics <- game_predictions |> metrics(truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "game_conf_mat <- game_predictions |>\n",
    "                        conf_mat(truth = subscribe, estimate = .pred_class) \n",
    "game_metrics\n",
    "game_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331203f6-6bc7-4a5d-ac98-483c392fcdda",
   "metadata": {},
   "source": [
    "The model appears to be performing well with an accuracy performance of 65% ,but this is not enough. It looks like the issue of class imbalance is really affecting our model because it did not predict any of the false subscription statuses as actually being false. Let's try this again by oversampling the observations with false subscription statuses. We will only upsample on the training data because we still need the original test dataset to evaluate whether our upsampling had any positive effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709b729-ccd9-4440-845b-0c3905950784",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_game_recipe <- recipe(subscribe ~ played_hours + Age, data = game_train) |>\n",
    "  step_upsample(subscribe, over_ratio = 1, skip = FALSE) |>\n",
    "  prep()\n",
    "\n",
    "game_train <- bake(new_game_recipe, game_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcebb4d-3ca1-4c36-acbc-118c4f46e3b6",
   "metadata": {},
   "source": [
    "Since upsampling changes the structure of our dataset, we will need to perform cross fold validation again. For cross validation we will increase the range of values of K because it looks like we are achieving higher accuracy for higher values of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295c4fe-e5d6-4245-88d4-52613e20a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234) \n",
    "new_game_vfold <- vfold_cv(game_train, v = 5, strata = subscribe)\n",
    "new_knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "            set_engine(\"kknn\") |>\n",
    "            set_mode(\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45b025-a85f-4d58-98d0-2b68c3c2d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2456)\n",
    "new_knn_results <- workflow() |>\n",
    "      add_recipe(game_recipe) |>\n",
    "      add_model(new_knn_tune) |>\n",
    "      tune_grid(resamples = new_game_vfold, grid = tibble(neighbors = seq(from = 1, to = 25, by = 1))) |>\n",
    "      collect_metrics()\n",
    "head(new_knn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17c4f0-9022-467f-9223-a663f5fe3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_accuracies <- new_knn_results |> \n",
    "      filter(.metric == \"accuracy\")\n",
    "\n",
    "new_accuracy_versus_k <- ggplot(new_accuracies, aes(x = neighbors, y = mean))+\n",
    "      geom_point() +\n",
    "      geom_line() +\n",
    "      labs(x = \"Neighbors\", y = \"Accuracy Estimate\", title = \"(Figure 3) Accuracy estimate for range of values of K after upsampling\") +\n",
    "      scale_x_continuous(breaks = seq(0, 25, by = 1)) +  # adjusting the x-axis\n",
    "      scale_y_continuous(limits = c(0.4, 1.0)) # adjusting the y-axis\n",
    "\n",
    "new_accuracy_versus_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c05c0d-509a-4b7d-adcf-c0ef8dde3c23",
   "metadata": {},
   "source": [
    "It looks like the highest performance comes from **K = 2**, excluding the performance for **K=1**. We will now train another model with **K = 2** and use it the test data to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced158cf-e2af-4d75-b8a5-b1acd11ca32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9999) \n",
    "newer_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 2) |>\n",
    "       set_engine(\"kknn\") |>\n",
    "       set_mode(\"classification\")\n",
    "\n",
    "new_game_fit <- workflow() |>\n",
    "             add_recipe(game_recipe) |>\n",
    "             add_model(newer_spec) |>\n",
    "            fit(data = game_train)\n",
    "new_game_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ed456-79a0-4a90-868c-e357dce1f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9999) \n",
    "\n",
    "\n",
    "new_game_predictions <- predict(new_game_fit, game_test) |>\n",
    "                        bind_cols(game_test)\n",
    "\n",
    "new_game_metrics <- new_game_predictions |> metrics(truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "new_game_conf_mat <- new_game_predictions |>\n",
    "                        conf_mat(truth = subscribe, estimate = .pred_class)\n",
    "new_game_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517611b3-5d24-4b81-b2f1-1519dbac61aa",
   "metadata": {},
   "source": [
    "#### Visualization of the analysis\n",
    "Reference: https://campus.datacamp.com/courses/modeling-with-tidymodels-in-r/classification-models?ex=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fcf1f0-9e12-40d5-8dd3-094e5581d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmplot <- new_game_conf_mat |> autoplot(type = \"heatmap\") +\n",
    "                labs(title = \"(Figure 4)Heatmap for Confusion Matrix for Model Performance on Test Data\") +\n",
    "                theme(text = element_text(size = 14)) +\n",
    "                scale_fill_gradient(low = \"#c4dbf5\", high = \"#0352ab\")\n",
    "cmplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a4806-610d-44fd-a10c-7d1f5f759476",
   "metadata": {},
   "source": [
    "Taking the `TRUE` label as the positive target, we can calculate the precision, recall and accuracy of our model. The precision is around 68%. The recall is around 42%. If we were to take the `FALSE` label as the positive target, the precision is around 22% and the recall is around 46%. Our overall accuracy is around 43% which is worse than our initial accuracy of 65%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00590f-cb93-4a32-a5ad-2708eacbb295",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29fb719-af8d-4289-86e0-7af7fb846f7b",
   "metadata": {},
   "source": [
    "#### Summary of our observation\n",
    "We have concluded that `played_hours` and `Age` are not enough to predict the subscription status of an individual. This is because the accuracy of the result of our `k-NN` prediction was even worse than pure guessing, with a rate of around 40%. This low accuracy could be due to **the poor original data split**, **the variables we chose being poor predictors**, or **a poor data set**. \n",
    "\n",
    "We have tried to improve the accuracy by **upsampling** the data; however, it has gotten even worse. This could be due to the fact that our method for upsampling was not the most ideal, which was limited by how much the course had taught so far. In the future, better upsampling methods would be chosen. What the upsampling we did in this case was purely increasing the number of observations by repeating the same observations over and over. A better way to upsample the dataset would be to generate new observations to give valuable new data.\n",
    "\n",
    "#### Expectations of findings\n",
    "This was not what we expected to find. Our model performed worse than just random guessing. We initially thought that, logically, the number of hours played and the age of the player should be enough to predict the subscription status. For example, we assumed that younger players were more likely to have higher numbers of hours played and thereby are more likely to subscribe. At a minimum, we expected at least an accuracy greater than 60%.\n",
    "\n",
    "#### Impact of findings\n",
    "Finding whether the **number of hours played** and the **age** variable could predict a player's **subscription status** could have numerous impacts. Firstly, game-related newsletter companies could use this to more strategically target their advertisement to specific demographics, such as young players or players with a higher number of hours played. Also, game companies could use this to identify less engaged players who are at risk of not subscribing to the newsletter and allow such companies to engage their efforts in making sure these players do subscribe. Furthermore, game developers could tailor in-game offers to individuals who are more likely to subscribe, thus potentially increasing revenue.\n",
    "\n",
    "#### Future questions\n",
    "Given our model's poor performance, a potential area of exploration could be **using more variables from the dataset to predict the subscription status**. For example, player experience level could also be used to predict subscription status. Furthermore, we could explore how subscription-related behaviour varies across different game genres. Perhaps in one genre we find that younger people are more likely to subscribe to a game-related newsletter, but is this applicable across all genres? Another possibility for exploration could be investigating how in-game performance relates to subscription status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5718634-17fb-40bc-9773-70ebb3b68d14",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "summarize what you found\n",
    "- We found that this data could not predict. not learning meaningfully.\n",
    "- model is worse than random guessing \n",
    "- add more data.\n",
    "- try more powerful model like random forest, logistic regression, svm, dec tree\n",
    "- add class weightages or undersample. \n",
    "discuss whether this is what you expected to find\n",
    "- NO. We expected higher accuracy. Positive cohensomething. More than 60% accuracy at minimum. reasons: using supervised learning.  \n",
    "discuss what impact could such findings have\n",
    "- increase advertising to specific age groups or demographics.\n",
    "- increased user engagement. e.g high user players would like more frequent updates.\n",
    "- \n",
    "discuss what future questions could this lead to\n",
    "\n",
    "\n",
    "\n",
    "- plans\n",
    "- Not best method(KNN deals very poorly with imbalance)\n",
    "- Data not enough more data to train it\n",
    "- Classes imbalanced\n",
    "- Model too simple\n",
    "- overfit/underfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30cf11-5b32-4a6c-9b97-ab8c93c978c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a10acc-3657-443d-aeb7-01b2b817974b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a6dc3-df47-49e1-8c1c-dfbbcbf51096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
